# ======================== Elasticsearch Configuration =========================
#
# NOTE: Elasticsearch comes with reasonable defaults for most settings.
#       Before you set out to tweak and tune the configuration, make sure you
#       understand what are you trying to accomplish and the consequences.
#
# The primary way of configuring a node is via this file. This template lists
# the most important settings you may want to configure for a production cluster.
#
# Please see the documentation for further information on configuration options:
# <http://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration.html>
#
# ---------------------------------- Cluster -----------------------------------
#
# Use a descriptive name for your cluster:
#
cluster:
    # 配置es的集群名称，默认是elasticsearch，es会自动发现在同一网段下的es，如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。
    name: x_es_cluster
    routing:
        allocation:
            # 初始化数据恢复时，并发恢复线程的个数，默认为4。
            node_initial_primaries_recoveries: 4
            # 添加删除节点或负载均衡时并发恢复线程的个数，默认为4。
            node_concurrent_recoveries: 2
#
# ------------------------------------ Node ------------------------------------
#
# Use a descriptive name for the node:
#
node:
    # 节点名，默认随机指定一个name列表中名字，该列表在es的jar包中config文件夹里name.txt文件中，其中有很多作者添加的有趣名字。
    name: x_node_1
    # 指定该节点是否有资格被选举成为node，默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master。
    master: true
    # 指定该节点是否存储索引数据，默认为true。
    data: true
#
# ------------------------------------ Index ------------------------------------
#
# index
#
index:
    # 设置默认索引分片个数，默认为5片。
    number_of_shards: 5
    # 设置默认索引副本个数，默认为1个副本。
    number_of_replicas: 1
    search:
        # 查询时的慢日志参数设置
        slowlog:
            level: TRACE
            threshold:
                query:
                    warn: 10s
                    info: 5s
                    debug: 2s
                    trace: 500ms
                fetch:
                    warn: 1s
                    info: 800ms
                    debug: 500ms
                    trace: 200ms
#
# Add custom attributes to the node:
#
# node.rack: r1
#
# ----------------------------------- Paths ------------------------------------
#
# Path to directory where to store the data (separate multiple locations by comma):
#
path:
    # 设置配置文件的存储路径，默认是es根目录下的config文件夹。
    conf: ${ES_HOME}/config
    # 设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开
    data: /data/elasticsearch/data
    # 设置临时文件的存储路径，默认是es根目录下的work文件夹。
    work: /data/elasticsearch/work
    # 设置插件的存放路径，默认是es根目录下的plugins文件夹
    plugins: ${ES_HOME}/plugins
    # 设置日志文件的存储路径，默认是es根目录下的logs文件夹
    logs: /data/elasticsearch/logs
#
# ----------------------------------- Memory -----------------------------------
#
# Lock the memory on startup:
#
bootstrap:
    # 设置为true来锁住内存。因为当jvm开始swapping时es的效率会降低，所以要保证它不swap
    # 可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值
    # 并且保证机器有足够的内存分配给es。
    # 同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过`ulimit -l unlimited`命令。
    mlockall: true
#
# Make sure that the `ES_HEAP_SIZE` environment variable is set to about half the memory
# available on the system and that the owner of the process is allowed to use this limit.
#
# Elasticsearch performs poorly when the system is swapping the memory.
#
# ---------------------------------- Network -----------------------------------
#
# Set the bind address to a specific IP (IPv4 or IPv6):
#
network:
    # 设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0。
    bind_host: 0.0.0.0
    # 设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。
    publish_host: 10.128.7.130
    # 这个参数是用来同时设置bind_host和publish_host上面两个参数。
    host: 127.0.0.1

transport:
    tcp:
        # 设置节点间交互的tcp端口，默认是9300。
        port: 9500
        # 设置是否压缩tcp传输时的数据，默认为false，不压缩。
        compress: true
#
# Set a custom port for HTTP:
#
http:
    # 设置对外服务的http端口，默认为9200。
    port: 9400
    # 设置内容的最大容量，默认100mb
    max_content_length: 100mb
    # 是否使用http协议对外提供服务，默认为true，开启。
    enabled: true
#
# For more information, see the documentation at:
# <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network.html>
#
# --------------------------------- Discovery ----------------------------------
#
discovery:
    zen:
        # 设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值（2-4）
        minimum_master_nodes: 1
        ping:
            # 设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。
            timeout: 3s
            multicast:
                # 设置是否打开多播发现节点，默认是true。
                enabled: true
            unicast:
                # 设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。
                hosts: ["127.0.0.1", "10.128.7.130"]
# Pass an initial list of hosts to perform discovery when new node is started:
# The default list of hosts is ["127.0.0.1", "[::1]"]
#
# discovery.zen.ping.unicast.hosts: ["host1", "host2"]
#
# Prevent the "split brain" by configuring the majority of nodes (total number of nodes / 2 + 1):
#
# discovery.zen.minimum_master_nodes: 3
#
# For more information, see the documentation at:
# <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html>
#
# ---------------------------------- Gateway -----------------------------------
#
# Block initial recovery after a full cluster restart until N nodes are started:
#
gateway:
    # 设置集群中N个节点启动时进行数据恢复，默认为1。
    recover_after_nodes: 1
    # 设置初始化数据恢复进程的超时时间，默认是5分钟。
    recover_after_time: 5m
    # 设置这个集群中节点的数量，默认为2，一旦这N个节点启动，就会立即进行数据恢复
    expected_nodes: 1

# indices
indices:
    recovery:
        # 设置数据恢复时限制的带宽，如入100mb，默认为0，即无限制。
        max_size_per_sec: 0
        # 设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为5。
        concurrent_streams: 5
#
# For more information, see the documentation at:
# <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-gateway.html>
#
# ---------------------------------- Various -----------------------------------
#
# Disable starting multiple nodes on a single system:
#
# node.max_local_storage_nodes: 1
#
# Require explicit names when deleting indices:
#
# action.destructive_requires_name: true
#
# ---------------------------------- Security -----------------------------------
#
# disable the JSM
#
security.manager.enabled: false

# snapshot/restore
repositories:
    # repository-hdfs plugin for snapshot/restore
    hdfs:
        uri: "hdfs://x86-ubuntu:9000/"
        path: "elasticsearch/snapshot_1"
        load_defaults: "true"
        conf_location: "/home/appd/app/hadoop/hadoop-2.7.1/etc/hadoop/core-site.xml,/home/appd/app/hadoop/hadoop-2.7.1/etc/hadoop/hdfs-site.xml"
        concurrent_streams: 5
        compress: "false"
        chunk_size: "10mb"
        # for kerberized hdfs
        conf.kerberos_config: "/etc/krb5.conf"
        conf.hdfs_config: "/home/appd/app/hadoop/hadoop-2.7.1/etc/hadoop/hdfs-site.xml"
        conf.hadoop_config: "/home/appd/app/hadoop/hadoop-2.7.1/etc/hadoop/core-site.xml"

